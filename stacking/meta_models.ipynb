{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-15T12:44:11.213712Z",
     "start_time": "2024-05-15T12:43:53.233441Z"
    }
   },
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from models.base_regressor import BaseRegressor\n",
    "import training as methods"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:51:29.706539Z",
     "start_time": "2024-05-15T12:51:11.016492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "####################\n",
    "# LOADING THE DATA #\n",
    "####################\n",
    "DATA_DIR = \"../segmented_data/\"\n",
    "\n",
    "SUBJECTS = ['AT', 'RB', 'RL']\n",
    "SCENES = ['FlatWalkStraight']\n",
    "TRIALS = ('all')\n",
    "\n",
    "def read_gait_cycles(subjects, scenes, trials):\n",
    "    # Adds the features of several past and future timesteps to each row\n",
    "    def expand_timeframe(gait_cycle):\n",
    "        NR_OF_TIMESTEPS = 6\n",
    "        past   = [ 2**i for i in range(NR_OF_TIMESTEPS)]\n",
    "        future = [-2**i for i in range(NR_OF_TIMESTEPS)]\n",
    "        for offset in past + future:\n",
    "            # Shift the relevant columns back/forwards in time\n",
    "            columns = [col for col in methods.INPUTS if not col.startswith('P')]\n",
    "            shifted = gait_cycle[columns].shift(offset)\n",
    "            # Rename shifted columns and concat to gait_cycle\n",
    "            timestep = offset * -2 # ms\n",
    "            shifted.columns = [f'{col}_{timestep}ms' for col in columns]\n",
    "            gait_cycle = pd.concat([gait_cycle, shifted], axis=1)\n",
    "        return gait_cycle\n",
    "    \n",
    "    # Removes the first and final (25) rows for which no target label is available\n",
    "    def remove_buffers(df):\n",
    "        cond = df.iloc[:, 0:8].sum(axis=1) != 0\n",
    "        first = df[cond].index[0]\n",
    "        last = df[cond].index[-1] + 1\n",
    "        return df[first:last]\n",
    "    \n",
    "    # Reads a single csv-file, expands the features and removes the buffers\n",
    "    def read_gait_cycle(filepath):\n",
    "        gait_cycle = pd.read_csv(filepath, header=0, names=methods.HEADER)\n",
    "        gait_cycle = expand_timeframe(gait_cycle)\n",
    "        return remove_buffers(gait_cycle)\n",
    "    \n",
    "    # Build up DataFrame of gait cyles by traversing the specified TRIALS\n",
    "    df = DataFrame()\n",
    "    for subdirs in itertools.product(subjects, scenes):\n",
    "        path = DATA_DIR + '/'.join(subdirs)\n",
    "        for file in os.listdir(path):\n",
    "            if file.endswith('.csv') and (file.startswith(trials) or trials == ('all')):\n",
    "                print(\"Reading\", file)\n",
    "                filepath = path + '/' + file\n",
    "                gait_cycle = read_gait_cycle(filepath)\n",
    "                gait_cycle['trial'] = file\n",
    "                gait_cycle['subject'] = subdirs[0]\n",
    "                df = pd.concat([df, gait_cycle])\n",
    "    return df\n",
    "\n",
    "\n",
    "gait_cycles = read_gait_cycles(SUBJECTS, SCENES, TRIALS)"
   ],
   "id": "f4f114765d09a890",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:51:29.876676Z",
     "start_time": "2024-05-15T12:51:29.706539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "###################\n",
    "# BASE-META SPLIT #\n",
    "###################\n",
    "df_base, df_meta = train_test_split(gait_cycles, test_size=0.5, random_state=42, stratify=gait_cycles['trial'])"
   ],
   "id": "6df7675a852577d0",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:51:30.147035Z",
     "start_time": "2024-05-15T12:51:29.876676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##############################################\n",
    "# LEFT VS. RIGHT FOOT -> MAIN VS. OTHER FOOT #\n",
    "##############################################\n",
    "def homogenize(df):\n",
    "    def rename_columns(df, main_foot, other_foot):\n",
    "        mapping = {col: col.replace(\"_\" + main_foot, \"\")\n",
    "                           .replace(\"_\" + other_foot, \"_o\")\n",
    "                   for col in df.columns}\n",
    "        return df.rename(columns=mapping)\n",
    "    # Create the new DataFrame\n",
    "    df_l = rename_columns(df, 'l', 'r')\n",
    "    df_r = rename_columns(df, 'r', 'l')\n",
    "    df_r = df_r[df_l.columns]\n",
    "    return df_l, df_r\n",
    "\n",
    "df_l, df_r = homogenize(df_base)\n",
    "df_homogenous = pd.concat([df_l, df_r])"
   ],
   "id": "6f259f3f7fc48026",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:51:30.693667Z",
     "start_time": "2024-05-15T12:51:30.147035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#############\n",
    "# FILTERING #\n",
    "#############\n",
    "df_filtered = methods.filter(df_homogenous)\n",
    "\n",
    "df_filtered.groupby(['trial']).count()"
   ],
   "id": "34609b5194129f74",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:51:34.304245Z",
     "start_time": "2024-05-15T12:51:30.695697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(30, 10))\n",
    "corr = df_filtered.iloc[:, :62].corr()\n",
    "corr_dep = corr.iloc[0:4]\n",
    "cmap = sns.diverging_palette(260, 20, s=75, l=40, n=5, center=\"light\", as_cmap=True)\n",
    "sns.heatmap(corr_dep, cmap=cmap, center=0, annot=True, fmt='.2f', square=True, robust=True, cbar=False)\n",
    "\n",
    "plt.show()"
   ],
   "id": "439f1cd7ffef78d0",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:51:34.508208Z",
     "start_time": "2024-05-15T12:51:34.304245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "####################\n",
    "# TRAIN-TEST SPLIT #\n",
    "####################\n",
    "df_full_train, df_test = train_test_split(df_filtered, test_size=0.2, random_state=42, stratify=df_filtered['trial'])"
   ],
   "id": "b49c9fef512f2ab6",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:51:34.759746Z",
     "start_time": "2024-05-15T12:51:34.508208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "############################\n",
    "# FEATURE/LABEL EXTRACTION #\n",
    "############################\n",
    "# Features\n",
    "X_full_train = methods.extract_features(df_full_train)\n",
    "X_test = methods.extract_features(df_test)\n",
    "\n",
    "print('X_full_train:', np.shape(X_full_train))\n",
    "\n",
    "# Labels\n",
    "Fx_full_train = df_full_train['Fx']\n",
    "Fy_full_train = df_full_train['Fy']\n",
    "Fz_full_train = df_full_train['Fz']\n",
    "M_full_train  = df_full_train['M']\n",
    "Fx_test = df_test['Fx']\n",
    "Fy_test = df_test['Fy']\n",
    "Fz_test = df_test['Fz']\n",
    "M_test  = df_test['M']\n",
    "\n",
    "print('Fx_full_train:', np.shape(Fx_full_train))\n",
    "\n",
    "# Partitions\n",
    "partition_full_train = df_full_train['trial']\n",
    "partition_test = df_test['trial']\n",
    "\n",
    "print('partition_full_train:', np.shape(partition_full_train))"
   ],
   "id": "914eae97bfe749a0",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:51:35.571783Z",
     "start_time": "2024-05-15T12:51:34.759746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DIR = '../results/' + time.strftime(\"%Y%m%d-%H%M%S/\", time.localtime())\n",
    "\n",
    "###############\n",
    "# PERFORM PCA #\n",
    "###############\n",
    "X_pc_full_train, X_pc_test = methods.perform_pca(X_full_train, X_test, DIR)\n",
    "nr_of_features = np.shape(X_pc_full_train)[1]"
   ],
   "id": "3cc8977d5935a7b",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:51:35.634789Z",
     "start_time": "2024-05-15T12:51:35.571783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "######################\n",
    "# CONVERT TO TENSORS #\n",
    "######################\n",
    "# Features\n",
    "X_full_train_tensor = torch.tensor(X_pc_full_train, dtype=torch.float32)\n",
    "X_test_tensor       = torch.tensor(X_pc_test, dtype=torch.float32)\n",
    "\n",
    "# Labels\n",
    "Fx_full_train_tensor = torch.tensor(Fx_full_train.to_numpy().reshape((-1, 1)), dtype=torch.float32)\n",
    "Fy_full_train_tensor = torch.tensor(Fy_full_train.to_numpy().reshape((-1, 1)), dtype=torch.float32)\n",
    "Fz_full_train_tensor = torch.tensor(Fz_full_train.to_numpy().reshape((-1, 1)), dtype=torch.float32)\n",
    "M_full_train_tensor  = torch.tensor(M_full_train.to_numpy().reshape((-1, 1)), dtype=torch.float32)\n",
    "Fx_test_tensor = torch.tensor(Fx_test.to_numpy().reshape((-1, 1)), dtype=torch.float32)\n",
    "Fy_test_tensor = torch.tensor(Fy_test.to_numpy().reshape((-1, 1)), dtype=torch.float32)\n",
    "Fz_test_tensor = torch.tensor(Fz_test.to_numpy().reshape((-1, 1)), dtype=torch.float32)\n",
    "M_test_tensor  = torch.tensor(M_test.to_numpy().reshape((-1, 1)), dtype=torch.float32)"
   ],
   "id": "eeabd4afa38ebb04",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:51:39.230412Z",
     "start_time": "2024-05-15T12:51:35.634789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################\n",
    "# Fx REGRESSOR #\n",
    "################\n",
    "Fx_regressor = BaseRegressor(nr_of_features, [42])\n",
    "Fx_regressor.train_(X_full_train_tensor, Fx_full_train_tensor)\n",
    "\n",
    "# Evaluate the model\n",
    "Fx_regressor.eval()\n",
    "Fx_pred_tensor = Fx_regressor(X_test_tensor)\n",
    "methods.print_metrics(Fx_test_tensor, Fx_pred_tensor)\n",
    "\n",
    "Fx_regressor.save(DIR, 'Fx_base')"
   ],
   "id": "74ce64e0559a6cfc",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:53:14.862768Z",
     "start_time": "2024-05-15T12:53:09.372597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################\n",
    "# Fy REGRESSOR #\n",
    "################\n",
    "Fy_regressor = BaseRegressor(nr_of_features, [42])\n",
    "Fy_regressor.train_(X_full_train_tensor, Fy_full_train_tensor)\n",
    "\n",
    "# Evaluate the model\n",
    "Fy_regressor.eval()\n",
    "Fy_pred_tensor = Fy_regressor(X_test_tensor)\n",
    "methods.print_metrics(Fy_test_tensor, Fy_pred_tensor)\n",
    "\n",
    "Fy_regressor.save(DIR, 'Fy_base')"
   ],
   "id": "5dc07c9c5c998ed3",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:53:17.259918Z",
     "start_time": "2024-05-15T12:53:14.868752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################\n",
    "# Fz REGRESSOR #\n",
    "################\n",
    "Fz_regressor = BaseRegressor(nr_of_features, [42])\n",
    "Fz_regressor.train_(X_full_train_tensor, Fz_full_train_tensor)\n",
    "\n",
    "# Evaluate the model\n",
    "Fz_regressor.eval()\n",
    "Fz_pred_tensor = Fz_regressor(X_test_tensor)\n",
    "methods.print_metrics(Fz_test_tensor, Fz_pred_tensor)\n",
    "\n",
    "Fz_regressor.save(DIR, 'Fz_base')"
   ],
   "id": "ae1cb912b132bb92",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:53:19.992887Z",
     "start_time": "2024-05-15T12:53:17.264877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "###############\n",
    "# M REGRESSOR #\n",
    "###############\n",
    "M_regressor = BaseRegressor(nr_of_features, [50])\n",
    "M_regressor.train_(X_full_train_tensor, M_full_train_tensor)\n",
    "\n",
    "# Evaluate the model\n",
    "M_regressor.eval()\n",
    "M_pred_tensor = M_regressor(X_test_tensor)\n",
    "methods.print_metrics(M_test_tensor, M_pred_tensor)\n",
    "\n",
    "M_regressor.save(DIR, 'M_base')"
   ],
   "id": "b3b44fa3e324a3c1",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:53:30.202247Z",
     "start_time": "2024-05-15T12:53:30.032225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#############################\n",
    "# SPLIT LEFT AND RIGHT FOOT #\n",
    "#############################\n",
    "# Remove rows with non-available values\n",
    "df_meta = df_meta.dropna()\n",
    "df_l, df_r = homogenize(df_meta)"
   ],
   "id": "3afe4227484ed357",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:53:31.586225Z",
     "start_time": "2024-05-15T12:53:31.196221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "############################\n",
    "# FEATURE/LABEL EXTRACTION #\n",
    "############################\n",
    "# Features\n",
    "X_l = methods.extract_features(df_l)\n",
    "X_r = methods.extract_features(df_r)\n",
    "\n",
    "print('X_l:', np.shape(X_l))\n",
    "\n",
    "# Labels\n",
    "Y_l = df_l[['Fx', 'Fy', 'Fz', 'M']]\n",
    "Y_r = df_r[['Fx', 'Fy', 'Fz', 'M']]\n",
    "\n",
    "print('Y_l:', np.shape(Y_l))\n",
    "\n",
    "# Partition\n",
    "partition_l = df_l['trial']\n",
    "partition_r = df_r['trial']\n",
    "\n",
    "print('partition_l:', np.shape(partition_l))"
   ],
   "id": "ce4cb7598e275ecf",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:53:32.241222Z",
     "start_time": "2024-05-15T12:53:32.015227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "###############\n",
    "# PERFORM PCA #\n",
    "###############\n",
    "pca = joblib.load(DIR + 'PCA.pkl')\n",
    "\n",
    "X_l_pc = pca.transform(X_l)\n",
    "X_r_pc = pca.transform(X_r)\n",
    "\n",
    "np.shape(X_l_pc)"
   ],
   "id": "9a3fba1382dd9275",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:53:32.890220Z",
     "start_time": "2024-05-15T12:53:32.851222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "######################\n",
    "# CONVERT TO TENSORS #\n",
    "######################\n",
    "# Features\n",
    "X_l_pc_tensor = torch.tensor(X_l_pc, dtype=torch.float32)\n",
    "X_r_pc_tensor = torch.tensor(X_r_pc, dtype=torch.float32)"
   ],
   "id": "e5190d82f8834dc8",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:53:34.112218Z",
     "start_time": "2024-05-15T12:53:33.806222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##################################\n",
    "# MAKING THE INITIAL PREDICTIONS #\n",
    "##################################\n",
    "Fx_l_pred = Fx_regressor(X_l_pc_tensor)\n",
    "Fy_l_pred = Fy_regressor(X_l_pc_tensor)\n",
    "Fz_l_pred = Fz_regressor(X_l_pc_tensor)\n",
    "M_l_pred  = M_regressor(X_l_pc_tensor)\n",
    "\n",
    "Fx_r_pred = Fx_regressor(X_r_pc_tensor)\n",
    "Fy_r_pred = Fy_regressor(X_r_pc_tensor)\n",
    "Fz_r_pred = Fz_regressor(X_r_pc_tensor)\n",
    "M_r_pred  = M_regressor(X_r_pc_tensor)"
   ],
   "id": "cc5ddd612ebff4f8",
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:53:34.287223Z",
     "start_time": "2024-05-15T12:53:34.235225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "###############################################\n",
    "# CREATING THE INPUT DATA FOR THE META MODELS #\n",
    "###############################################\n",
    "# Add inital predictions to input\n",
    "X_l_tensor = torch.cat((X_l_pc_tensor, Fx_l_pred, Fy_l_pred, Fz_l_pred, M_l_pred, Fx_r_pred, Fy_r_pred, Fz_r_pred, M_r_pred), dim=1)\n",
    "X_r_tensor = torch.cat((X_r_pc_tensor, Fx_l_pred, Fy_l_pred, Fz_l_pred, M_l_pred, Fx_r_pred, Fy_r_pred, Fz_r_pred, M_r_pred), dim=1)\n",
    "\n",
    "nr_of_features = np.shape(X_l_tensor)[1]\n",
    "\n",
    "nr_of_features"
   ],
   "id": "5447775730b94880",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:53:35.715223Z",
     "start_time": "2024-05-15T12:53:35.410221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#############\n",
    "# FILTERING #\n",
    "#############\n",
    "def filter(X_tensor, Y_df, partition, df):\n",
    "    mask = ((df['fp1'] != 1)\n",
    "            & (df['valid_mask_feet'] == 1)\n",
    "            & (df['correct_mask_ins'] == 1)\n",
    "            & ((df['Ftot'] < 0.05) | (df['Fz'] != 0))).values\n",
    "    \n",
    "    return X_tensor[mask], Y_df[mask], partition[mask]\n",
    "\n",
    "X_l_filtered_tensor, Y_l_filtered, partition_l_filtered = filter(X_l_tensor, Y_l, partition_l, df_l)\n",
    "X_r_filtered_tensor, Y_r_filtered, partition_r_filtered = filter(X_r_tensor, Y_r, partition_r, df_r)\n",
    "\n",
    "print(np.shape(X_l_filtered_tensor))\n",
    "print(np.shape(Y_l_filtered))\n",
    "\n",
    "# Concat left and right foot\n",
    "X_filtered_tensor = torch.cat((X_l_filtered_tensor, X_r_filtered_tensor), dim=0)\n",
    "Y_filtered = pd.concat([Y_l_filtered, Y_r_filtered], axis=0)\n",
    "partition_filtered = pd.concat([partition_l_filtered, partition_r_filtered], axis=0)\n",
    "\n",
    "print(np.shape(X_filtered_tensor))\n",
    "print(np.shape(Y_filtered))\n",
    "print(np.shape(partition_filtered))"
   ],
   "id": "8bacdc8140175440",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:53:35.920224Z",
     "start_time": "2024-05-15T12:53:35.800232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "####################\n",
    "# TRAIN-TEST SPLIT #\n",
    "####################\n",
    "X_full_train, X_test, Y_full_train, Y_test = train_test_split(X_filtered_tensor.detach().numpy(), Y_filtered, test_size=0.2, random_state=42, stratify=partition_filtered)"
   ],
   "id": "fd8b9bf7f845c6ca",
   "execution_count": 31,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:53:37.361224Z",
     "start_time": "2024-05-15T12:53:37.302221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "######################\n",
    "# CONVERT TO TENSORS #\n",
    "######################\n",
    "# Features\n",
    "X_full_train_tensor = torch.tensor(X_full_train, dtype=torch.float32)\n",
    "X_test_tensor       = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "# Labels\n",
    "Fx_full_train_tensor = torch.tensor(Y_full_train['Fx'].to_numpy().reshape((-1, 1)), dtype=torch.float32)\n",
    "Fy_full_train_tensor = torch.tensor(Y_full_train['Fy'].to_numpy().reshape((-1, 1)), dtype=torch.float32)\n",
    "Fz_full_train_tensor = torch.tensor(Y_full_train['Fz'].to_numpy().reshape((-1, 1)), dtype=torch.float32)\n",
    "M_full_train_tensor  = torch.tensor(Y_full_train['M'].to_numpy().reshape((-1, 1)), dtype=torch.float32)\n",
    "Fx_test_tensor = torch.tensor(Y_test['Fx'].to_numpy().reshape((-1, 1)), dtype=torch.float32)\n",
    "Fy_test_tensor = torch.tensor(Y_test['Fy'].to_numpy().reshape((-1, 1)), dtype=torch.float32)\n",
    "Fz_test_tensor = torch.tensor(Y_test['Fz'].to_numpy().reshape((-1, 1)), dtype=torch.float32)\n",
    "M_test_tensor  = torch.tensor(Y_test['M'].to_numpy().reshape((-1, 1)), dtype=torch.float32)"
   ],
   "id": "ee04971c8a0e016d",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:53:43.244550Z",
     "start_time": "2024-05-15T12:53:37.369225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#################\n",
    "# Fx META-MODEL #\n",
    "#################\n",
    "Fx_meta = BaseRegressor(nr_of_features, [42])\n",
    "Fx_meta.train_(X_full_train_tensor, Fx_full_train_tensor)\n",
    "\n",
    "# Evaluate the model\n",
    "Fx_meta.eval()\n",
    "Fx_pred_tensor = Fx_meta(X_test_tensor)\n",
    "methods.print_metrics(Fx_test_tensor, Fx_pred_tensor)\n",
    "\n",
    "Fx_meta.save(DIR, 'Fx_meta')"
   ],
   "id": "bde0b81907d727f7",
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:53:45.642006Z",
     "start_time": "2024-05-15T12:53:43.254548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#################\n",
    "# Fy META-MODEL #\n",
    "#################\n",
    "Fy_meta = BaseRegressor(nr_of_features, [42])\n",
    "Fy_meta.train_(X_full_train_tensor, Fy_full_train_tensor)\n",
    "\n",
    "# Evaluate the model\n",
    "Fy_meta.eval()\n",
    "Fy_pred_tensor = Fy_meta(X_test_tensor)\n",
    "methods.print_metrics(Fy_test_tensor, Fy_pred_tensor)\n",
    "\n",
    "Fy_meta.save(DIR, 'Fy_meta')"
   ],
   "id": "3efc2b35cdfa62bc",
   "execution_count": 34,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:53:47.938393Z",
     "start_time": "2024-05-15T12:53:45.642006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#################\n",
    "# Fz META-MODEL #\n",
    "#################\n",
    "Fz_meta = BaseRegressor(nr_of_features, [42])\n",
    "Fz_meta.train_(X_full_train_tensor, Fz_full_train_tensor)\n",
    "\n",
    "# Evaluate the model\n",
    "Fz_meta.eval()\n",
    "Fz_pred_tensor = Fz_meta(X_test_tensor)\n",
    "methods.print_metrics(Fz_test_tensor, Fz_pred_tensor)\n",
    "\n",
    "Fz_meta.save(DIR, 'Fz_meta')"
   ],
   "id": "d322752320871e0f",
   "execution_count": 35,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:53:50.163141Z",
     "start_time": "2024-05-15T12:53:47.938393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################\n",
    "# M META-MODEL #\n",
    "################\n",
    "M_meta = BaseRegressor(nr_of_features, [42])\n",
    "M_meta.train_(X_full_train_tensor, M_full_train_tensor)\n",
    "\n",
    "# Evaluate the model\n",
    "M_meta.eval()\n",
    "M_pred_tensor = M_meta(X_test_tensor)\n",
    "methods.print_metrics(M_test_tensor, M_pred_tensor)\n",
    "\n",
    "M_meta.save(DIR, 'M_meta')"
   ],
   "id": "7a2f8dbc91b71e7",
   "execution_count": 36,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "65c6de1603f46353",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
